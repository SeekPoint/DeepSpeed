关于Deepspeed的一些总结与心得
https://zhuanlan.zhihu.com/p/650824387
白板笔

使用场景：大规模深度学习训练，如训练大模型
使用范围：多机多卡，单机多卡，单机单卡
使用方式：通过json的参数配置文件完成

        DeepSpeed分布式启动器各命令含义
Argument	        Meaning	                        Example
master_port	        主节点的端口号	                    --master_port 29500
master_addr	        主节点的ip	                    --master_addr=10.51.97.28 (ifconfig->eth0->inet)
nnodes	            节点数	                        两台机器，--nnodes=2
node_rank	        节点rank，以第一台机器为0开始递增	--node_rank=0 master,即主节点rank
nproc_per_node	    每个节点的进程数	                一个节点使用八张卡，nproc_per_node=8

        关于NCCL(NVIDIA Collective Communications Library)参数的使用说明
参数                  	    意义	                    说明
NCCL_IB_DISABLE	        禁用IB网卡传输端口	        IB (InfiniBand)是一种用于高性能计算的计算机网络通信标准。

NCCL_SHM_DISABLE	    禁用共享内存传输	        共享内存(SHM)传输支持运行在相同处理单元/机器中的实体之间的快速通信，
                                                这依赖于主机操作系统提供的共享内存机制

NCCL_P2P_DISABLE	    禁用GPU之间信息的传输	    P2P使用CUDA和NVLink直接实现GPU之间的传输与访问

关于如何查看GPU是否支持 NVLINK

使用命令

nvidia-smi topo -p2p n
V100 上显示结果 (不支持）
003.webp

A800 上显示结果 (支持）
004.webp


启动器示例
    //  多机多卡命令通常为（torchrun启动器）:
     /bin/bash
     -c
     echo $RANK, $HOSTNAME, $MASTER_PORT && if [ $RANK -eq 0 ]; then export MASTER_ADDR=$HOSTNAME; fi && echo $MASTER_ADDR && NCCL_IB_DISABLE=1 NCCL_SHM_DISABLE=1 NCCL_P2P_DISABLE=1 NCCL_DEBUG=INFO torchrun --nproc_per_node=8 --nnodes=2 --node_rank=${RANK} --master_addr=${MASTER_ADDR} --master_port ${MASTER_PORT} train.py --model_config_file train_config.json --deepspeed deepspeed_config.json --iterable_dataset

     /*
      echo $RANK, $HOSTNAME, $MASTER_PORT && if [ $RANK -eq 0 ]; then export MASTER_ADDR=$HOSTNAME; fi && echo $MASTER_ADDR : 先在终端打印出 `$RANK`、`$HOSTNAME` 和 `$MASTER_PORT` 的值，然后根据 `$RANK` 的值来设置 `$MASTER_ADDR` 的值，并最后打印出 `$MASTER_ADDR` 的值。

       可以在torchrun前进行 NCCL参数的调整
       NCCL_DEBUG=INFO 显示调试信息

     --nproc_per_node 每个节点的进程数
     --nnodes 节点数
     --node_rank 节点的等级
     --master_addr 主节点的ip
     --master_port 主节点的端口号

     --model_config_file 选择模型参数文件
     --deepspeed 选择deepspeed参数文件
     */

在 --deepspeed 处，deepspeed参数请选择deepspeed_config.json的json配置文件

通过该配置文件，你可以进行以下主要功能的选择与调整

1. 优化器状态切分 (ZeRO stage 1)

2. 梯度切分 (ZeRO stage 2)

3. 参数切分 (ZeRO stage 3)

4. 混合精度训练 (mixed precision training)

5. ZeRO-Offload to CPU and NVMe

除此之外，你还可以通过该文件进行其他功能配置的调整

6.批量大小相关参数 (Batch size)

7. 优化器相关参数 (Optimizer)

8. 调度器 (scheduler)

9. 其他


介绍部分

通信原语

Broadcast：
一对多的通信原语，一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据广播到其他节点上。

Scatter：
一对多的通信原语，也是一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据发散到其他节点上。
与Broadcast不同的是，Broadcast把主节点0的数据发送给所有节点，而Scatter则是将数据进行切片再分发给集群内所有的节点。

Gather：
多对一的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据收集到一个节点上。

AllGather：
多对多的通信原语，具有多个数据发送者，多个数据接收者，可以在集群内把多个节点的数据收集到一个主节点上（Gather），
再把这个收集到的数据分发到其他节点上（broadcast），即收集集群内所有的数据到所有的节点上。

Reduce：
多对一的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据规约运算到一个主节点上，
常用的规约操作符有：求累加和SUM、求累乘积PROD、求最大值MAX、求最小值MIN、逻辑与LAND、按位与BAND、
逻辑或LOR、按位或BOR、逻辑异或LXOR、按位异或BOXR、求最大值和最小大的位置MAXLOC、求最小值和最小值的位置MINLOC等，
这些规约运算也需要加速卡支持对应的算子才能生效。

ReduceScatter：
多对多的通信原语，具有多个数据发送者，多个数据接收者，在集群内的所有节点上都按维度执行相同的Reduce规约运算，
再将结果发散到集群内所有的节点上。Reduce-scatter等价于节点个数次的reduce规约运算操作，再后面执行节点个数的scatter次操作。
其反向操作是AllGather。

AllReduce：
多对多的通信原语，具有多个数据发送者，多个数据接收者，在集群内的所有节点上都执行相同的Reduce操作，
可以将集群内所有节点的数据规约运算得到的结果发送到所有的节点上。

主要功能

Zero redundancy optimizer
ZeRO-DP是一种通过将内存占用划分到多张卡或者多个节点的支持超大规模模型训练的数据并行技术，是DeepSpeed库的核心功能之一。
传统的数据并行或者模型并行方法要么会大幅度降低计算效率，要么对内存的节省不是很友好，
而ZeRO-DP在实现数据并行高效计算的同时，拥有模型并行的内存节省优势，很好地优化了模型状态内存

005.webp

ZeRO-DP


ZeRO-DP 主要有三个优化阶段，分别对应了模型状态中优化器状态、梯度，以及模型参数的切分，也就是通常所说的ZeRO-1/2/3

ZeRO-1： 优化器状态切分（Pos）：
切分优化器状态到各个计算卡中，在享有与普通数据并行相同通信量的情况下，可降低4倍的内存占用。

ZeRO-2： 添加梯度切分（Pos+g）：
在Pos的基础上，进一步将模型梯度切分到各个计算卡中，在享有与普通数据并行相同通信量的情况下，拥有8倍的内存降低能力。

ZeRO-3： 添加参数切分（Pos+g+p）：
在Pos+g的基础上，将模型参数也切分到各个计算卡中，内存降低能力与并行数量成线性比例，通信量大约有50%的增长。

mixed precision training
通常模型会使用float32(fp32)精度进行训练，但是随着模型越来越大，训练的硬件成本和时间成本急剧增加。
而混合精度训练通过利用float16(fp16)的优点并规避缺点来进行训练。

fp32,fp16,bf16的区别如下图所示

006.webp
fp32/fp16/bf16 区别


优点：

1.降低显存占用，float16比float32小一半；

2.减少网络通信开销；

3.硬件针对fp16优化，速度更快

缺点：

1.下溢。
对于深度学习来说，float16最大的问题是"下溢"。
模型的更新通常是 ，随着模型的训练，这个值往往会很小，可能会超出float16表示的精度。
结果就是：大多数的模型权重都不再更新，模型难以收敛。

2.舍入误差。
模型权重和梯度相差太大，通过梯度更新权重并进行舍入时，可能导致更新前和更新后的权重没有变化。

bf16是一种全新的数字格式，更加支持深度学习计算，但需要硬件支持，如NVIDIA A100, NVIDIA A800等

此外，官方文档中提到了AMP(Auto Mixed Precision 自动混合精度训练) ，与ZeRO不能同时使用

offload
在中间变量产生时，将中间变量移动到 CPU/NVMe 上，在需要使用中间变量时移动到 GPU 上。
通过这种方式，可以减小中间变量的显存占用。Zero的Offload优化通常更适用于资源受限，但是又要训练大模型的情况。
通过时间换空间。比如把optimizer state, parameters offload到CPU/NVMe，会有一些额外的时间开销

参数配置信息示例
    ZeRO-0：
    "zero_optimization": {
            "stage": 0
        }
禁用所有分片，此时将DeepSpeed视为DDP使用 (stage默认值：0)

ZeRO-1：
    "zero_optimization": {
            "stage": 1
        }
ZeRO第一阶段的优化，将优化器状态进行切分。

ZeRO-2：
    "zero_optimization": {
            "stage": 2,
            "allgather_partitions": true,
            "allgather_bucket_size": 3e8,
            "overlap_comm": true,
            "reduce_scatter": true,
            "reduce_bucket_size": 3e8,
            "contiguous_gradients": true
        }

allgather_partitions：
在每个步骤结束时，从所有GPU中选择使用allgather集体操作或一系列广播集体操作之间的方式，以收集更新后的参数。 (默认值：true)

allgather_bucket_size：
用于调节Allgather操作的分桶大小。将张量分成较小的桶有助于在通信过程中更高效地传输数据。
较大的allgather_bucket_size值会导致每个桶的尺寸增大，可能加速通信操作，但也需要更多内存来存储中间结果。
选择合适的桶大小需要根据实际情况进行调整。(默认值：5e8)

overlap_comm：
控制通信与计算是否交叠执行。当设置为True时，DeepSpeed将尝试在梯度计算期间并行进行梯度通信。
这有效地缩短通信时间，从而加速整个训练过程。(默认值：false)

reduce_scatter：
使用reduce或reduce scatter来替代allreduce以平均梯度。(默认值：true)

reduce_bucket_size：
用于控制Allreduce操作的分桶大小。将张量分为较小的桶有助于数据在通信过程中的更高效传输。
随着reduce_bucket_size值的增大，每个桶的尺寸也随之增大，这或许能加速通信操作，但同时也需要更多内存来存储中间结果。
合适的桶大小应根据实际情况进行适当调整。(默认值：5e8)

contiguous_gradients：
在梯度产生时将其复制到一个连续的缓冲区中。在反向传播过程中避免了内存碎片化问题。(默认值：true)

ZeRO-3
"zero_optimization": {
        "stage": 3,
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": 1e6,
        "stage3_prefetch_bucket_size": 4e6,
        "stage3_param_persistence_threshold": 1e4,
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9,
        "stage3_gather_16bit_weights_on_model_save": true
    },
sub_group_size：
控制在优化器步骤中参数更新的粒度。参数被分组到大小为sub_group_size的桶中，每个桶依次进行一次更新。
当与ZeRO-Infinity中的NVMe offload同时使用时，sub_group_size决定了在优化器步骤期间从NVMe迁移到CPU内存的模型状态的粒度。
这有助于避免超大模型对CPU内存的过度占用。在不使用NVMe offload时，请保持其默认值。
若遇到内存不足（OOM）情况，可以考虑减小sub_group_size。
当优化器迭代较缓慢时，也可以考虑增大sub_group_size。(默认值：1e9)

stage3_prefetch_bucket_size：
预取参数的固定缓冲区大小。较小的值使用的内存较少，但可能会因通信而增加停顿。(默认值：5e8)

stage3_max_live_parameters：
保留在GPU上的完整参数数量的上限。(默认值：1e9)

stage3_max_reuse_distance：
根据参数在未来何时再次使用的指标来决定是舍弃还是保留参数。
如果一个参数在不久的将来会再次被使用（小于stage3_max_reuse_distance），则会保留该参数以减少通信开销。
在遇到内存不足（OOM）的情况下，可以降低stage3_max_live_parameters和stage3_max_reuse_distance的值。(默认值：1e9)

stage3_gather_16bit_weights_on_model_save：
在保存模型时启用模型FP16权重合并。对于大型模型和多GPU环境，这是一项在内存和速度方面代价较高的操作。(默认值：false)

ZeRO-3 中不使用 allgather_partitions、allgather_bucket_size 和 reduce_scatter 配置参数

（其他参数如grad_hooks、round_robin_gradients本文未提及）

offload
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },

        "offload_param": {
            "device": "nvme",
            "pin_memory": true
        }

在开启ZeRO第一阶段后，可以使用offload_optimizer，
在开启ZeRO第三阶段后才可以同时使用offload_optimizer与offload_param

pin_memory:
转移到页面锁定的CPU内存。
这可能会提升吞吐量，但代价是增加了额外的内存开销。(默认值：false)

offload to NVMe
注意：offload to NVMe 只在stage 3开启后才能使用！

        "offload_optimizer": {
            "device": "nvme",
            "nvme_path": "/dev/shm",
            "buffer_count": 4,
            "fast_init": false
        },

        "offload_param": {
            "device": "nvme",
            "nvme_path": "/dev/shm",
            "buffer_count": 5,
            "buffer_size": 1e8,
            "max_in_cpu": 1e9
        }

nvme_path:
用于卸载优化器/参数的NVMe设备的文件系统路径。

buffer_count(offload_optimizer):
用于将优化器状态卸载到NVMe的缓冲池中的缓冲区数量。这个数量至少应该是优化器每个参数维护的状态数。
例如，Adam优化器有4个状态（参数、梯度、动量和方差）。 (默认值：5)

fast_init:
启用在卸载至NVMe时的快速优化器初始化。 (默认值：false)

buffer_count(offload_param):
将参数卸载到NVMe的缓冲池中的缓冲区数量。 (默认值：5)

buffer_size:
将参数卸载到NVMe的缓冲池中的缓冲区大小。 (默认值：1e8)

max_in_cpu:
启用卸载至NVMe时在CPU内存中保留的参数元素数量。 (默认值：1e9)

混合精度训练
"fp16": {
    "enabled": true,
    "auto_cast": false,
    "loss_scale": 0,
    "initial_scale_power": 16,
    "loss_scale_window": 1000,
    "hysteresis": 2,
    "consecutive_hysteresis": false,
    "min_loss_scale": 1
}


"bf16": {
   "enabled": true
 }

auto_cast：
是否将输入强制转换为fp16数据类型 (默认值：false)

loss_scale：
表示FP16训练的损失缩放值。默认值0.0启用动态损失缩放，否则该值将用于静态固定损失缩放 (默认值：0.0)

initial_scale_power：
表示初始动态损失比例值的功率，实际损失规模计算为 2^initial_scale_power (默认值：16)

loss_scale_window：
代表动态损失缩放值上升/下降的窗口范围。(默认值：1000)

hysteresis：
表示动态损耗缩放中的延迟偏移 (默认值：2)

consecutive_hysteresis：
表示是否在达到不会溢出的迭代时重新填充滞后。(默认值：false)

min_loss_scale：
表示最小动态损失比例值 (默认值：1)

007.png
注意：开启fp16后可能出现如上图所示overflow情况

BF16：
配置以bfloat16浮点格式作为FP16的替代方式。bfloat16需要硬件支持（例如，NVIDIA A100）。
使用bfloat16进行训练不需要损失缩放。(默认值：false)

批量大小相关参数

    "train_batch_size": "auto",

    "gradient_accumulation_steps": "auto",

    "train_micro_batch_size_per_gpu": "auto",

train_batch_size：
有效的训练批量大小。这指的是每次模型更新所涉及的数据样本数量。
train_batch_size是单个GPU在一次前向/后向传递中处理的批量大小，也称为train_micro_batch_size_per_gpu，
以及梯度累积步骤（也称为gradient_accumulation_steps），还有GPU数量，这些因素共同决定。
如果同时提供train_micro_batch_size_per_gpu和gradient_accumulation_steps，可以忽略train_batch_size。(默认值：32)

gradient_accumulation_steps：
在计算平均并应用梯度之前累积梯度的训练步骤数。这个功能有时候对于提高可扩展性非常有用，因为它减少了步骤之间梯度通信的频率。
另一个影响是，可以在每个GPU上使用更大的批量大小进行训练。
如果同时提供train_batch_size和train_micro_batch_size_per_gpu，可以忽略gradient_accumulation_steps。(默认值：1)

train_micro_batch_size_per_gpu：
单个GPU在一个步骤中处理的微批量大小（不进行梯度累积）。
如果同时提供train_batch_size和gradient_accumulation_steps，可以忽略train_micro_batch_size_per_gpu。
(默认值：train_batch_size的值)

train_batch_size = train_micro_batch_size_per_gpu * gradient_accumulation * number of GPUs.
（即训练批次的大小 = 每个GPU上的微批次大小 * 几个微批次 * 几个GPU）

优化器

"optimizer": {
        "type": "Adam",
        "params": {
            "lr": "auto",
            "betas": [
                0.9,
                0.95
            ],
            "eps": "auto",
            "weight_decay": "auto"
            "torch_adam": true,
            "adam_w_mode": true
        }
    },

type：
优化器名称。DeepSpeed原生支持Adam、AdamW、OneBitAdam、Lamb和OneBitLamb优化器，
并将从torch导入其他优化器。 (其他类型可查阅官方文档)

params：
参数字典，用于实例化优化器。
参数名称必须与优化器构造函数的签名相匹配（例如，对于Adam优化器）。例如：{"lr": 0.001, "eps": 1e-8}。

torch_adam：
使用torch的Adam实现，而不是融合Adam实现。 (默认值：false)

adam_w_mode：
应用L2正则化（也称为AdamW）。 (默认值：true)

调度器
"scheduler": {
        "type": "WarmupDecayLR",
        "params": {
            "warmup_min_lr": 5e-6,
            "warmup_max_lr": "auto",
            "warmup_num_steps": "auto",
            "total_num_steps": "auto"
        }
    },

DeepSpeed提供了 LRRangeTest、OneCycle、WarmupLR、WarmupDecayLR 学习率调度器的实现。
当使用DeepSpeed的学习率调度器（在deepspeed_config.json文件中指定）时，
DeepSpeed会在每个训练步骤（执行model_engine.step()时）调用调度器的step()方法。(其他类型可查阅官方文档)

warmup_min_lr：
最小学习率。 (默认值：0)

warmup_max_lr：
最大学习率。 (默认值：0.001)

warmup_num_steps：
从min_lr到max_lr的warm-up步数。 (默认值：1000)

total_num_steps：
训练总步数。

其他

    "gradient_clipping": 1.0,

    //Logging
    "steps_per_print": 10,
    "wall_clock_breakdown": false,
    "dump_state":false

gradient_clipping:
启用梯度剪裁，剪裁阈值为指定值。(默认值：1.0)

steps_per_print：
每经过N个训练步骤打印进度报告。
报告内容包括训练步骤数，由于混合精度训练中的溢出而跳过的优化器更新数，当前学习率以及当前动量。(默认值：10)

wall_clock_breakdown：
启用前向、反向和更新训练阶段的时序计时，以分析时间延迟。(默认值：false)

dump_state：
在初始化后打印出DeepSpeed对象的状态信息。(默认值：false)

关于auto
可以发现，配置示例中有参数被设置为auto。由于DeepSpeed目前已经被集成到了HuggingFace Transformer框架。
而DeepSpeed的很多参数，和Transformer的Trainer参数设置是一模一样的。
因此，官方推荐将很多常用的模型训练参数，设置为auto，在使用Trainer进行训练的时候，
这些值都会自动更新为Trainer中的设置，或者帮你自动计算。

大多数情况下只需要注意DeepSpeed-specific参数(如:ZeRO,offload)。
其他和Trainner重复的参数项，强烈建议设置成auto。

其他deepspeed功能如 Autotuning,
Model compression 等请参考官方文档 https://www.deepspeed.ai/docs/config-json/

对比实验
以下是进行的关于 deepspeed 主要功能的对比实验

实验基本deepspeed配置信息

(训练资源配置：master=1,worker=1 A800 双机8卡)

    // 实验使用 torchrun 启动器进行启动
    {
        "train_batch_size": "auto",
        "optimizer": {
            "type": "Adam",
            "params": {
                "lr": "auto",
                "betas": [
                    0.9,
                    0.95
                ],
                "eps": "auto",
                "weight_decay": "auto"
            }
        },
        "scheduler": {
            "type": "WarmupDecayLR",
            "params": {
                "warmup_min_lr": 5e-6,
                "warmup_max_lr": "auto",
                "warmup_num_steps": "auto",
                "total_num_steps": "auto"
            }
        },
        "steps_per_print": 10,
        "bf16": {
            "enabled": true
        },
        "gradient_clipping": 1.0,
        "zero_optimization": {
            "stage": 3,
            "offload_param": {
                "device": "cpu",
                "pin_memory": true
            },
            "offload_optimizer": {
                "device": "cpu",
                "pin_memory": true
            },
            "overlap_comm": true,
            "contiguous_gradients": true,
            "sub_group_size": 1e9,
            "reduce_bucket_size": "auto",
            "stage3_prefetch_bucket_size": "auto",
            "stage3_param_persistence_threshold": "auto",
            "stage3_max_live_parameters": 1e9,
            "stage3_max_reuse_distance": 1e9,
            "stage3_gather_16bit_weights_on_model_save": true
        },
        "gradient_accumulation_steps": "auto",
        "train_micro_batch_size_per_gpu": "auto",
        "wall_clock_breakdown": false
    }

实验一：关于开启ZeRO-3后关于不同offload设置对比实验结果如下

基于 Starcoder 模型代码共跑20个steps的结果（所有实验皆使用bf16）

deepspeed状态	                                        RunningAvgSamplesPerSec	    Train Runtime

stage3+offload  optimizer+offload  param	                    1.0935	                2421.5168

stage3+offload  optimizer+offload  param(pin memory is false)	1.0452	                2526.1535

stage3+offload  optimizer	                                    1.0969	                2412.6343

stage3+offload  optimizer+offload  param(offload to NVMe)	    0.8054	                3253.8819

结论：
使用ZeRO阶段三时，开启pin memory后吞吐率稍微加快。
是否开启offload parameter对实际吞吐率影响比较小。将offload目标改为NVMe后，吞吐率下降明显。

建议：
开启ZeRO阶段三后，若显存容量较小，可以将offload optimizer与offload parameter全部开启，并且开启pin memory，
若显存仍然不够，可以尝试将offload的地址修改为NVMe，但需要输入NVMe的路径，但必须接受训练速度变慢的可能。

实验二：关于不同ZeRO状态的对比实验
基于 Starcoder 模型代码共跑50个steps的结果，输入大小减小至实验一的0.125倍（所有实验皆使用bf16）

deepspeed状态	                            RunningAvgSamplesPerSec	        Train Runtime
stage3+offload optimizer+offload param	    3.7293771965509723	            1747.8949
stage3	                                    5.829033453986385	            1135.5075
stage2+offload optimizer	                3.315018655639157	            1972.8136
stage2	                                    8.012945453668733	            836.4292
stage1+offload optimizer	                7.338698238576821	            940.7128
stage1	                                    10.81689575732172	            632.3842

结论：在未开启offload的情况下，训练速度为
Stage 1 > stage 2 > stage 3

在开启offload（将能开启的全部开启）后，训练速度为
stage 1 > stage 3 > stage 2

建议：
stage 3如果在其他配置相同的情况下，很可能比stage 2要慢，因为前者除了执行stage 2的操作外，还需要收集模型权重。
但经实验结果显示，在多GPU的情况下将stage3的状态全部开启后，相对比stage2快一些。
如果stage 2满足需求，而且不需要在少数几个GPU之外进行扩展，那么您可以选择继续使用它。若显存足够，可以使用stage 1.

实验三：fp16与bf16的对比实验

基于 Starcoder 模型代码共跑50个steps的结果，输入大小减小至实验一的0.125倍，
实验使用stage3+offload optimizer+offload param 进行测试

Test Name	        RunningAvgSamplesPerSec	        Train Runtime
bf16	                3.7293771965509723	            1747.8949
fp16	                3.7056795533063427	            1797.7266

结论：使用bf16训练快于fp16

建议：若硬件支持，请选择bf16进行训练

实验四：关于NCCL三个参数的对比实验

基于 Starcoder 模型代码在实验一的条件下共跑50个steps的结果

参数	                        是否禁用
NCCL_IB_DISABLE	        1	0	0	1	1	1	0	0
NCCL_SHM_DISABLE	    1	1	1	1	0	0	0	0
NCCL_P2P_DISABLE	    1	1	0	0	1	0	1	0
Train Runtime	        2:37:14	2:36:22	1:44:18	1:50:12	2:21:38	1:43:53	2:20:29	1:43:40
RunningAvgSamplesPerSec	0.697	0.698	1.075	1.087	0.788	1.089	0.789	1.089

结论：
经过对比可以发现，将IB,SHM,P2P传输全都禁用后运行速度最慢，全部开启后运行速度最快。
此外，发现将P2P禁用，即禁用NVlink对于训练速度影响最大；
，同时禁用IB,SHM对训练时间会有影响，但影响较弱，会略微增加训练时长，单独禁用对训练无影响

建议：
为了更快的训练速度，如果机器允许，请不要开启任何一个禁用。

如何选择最佳性能的ZeRO阶段和offload方式

一般而言，以下规则适用：

从速度角度来看 Stage 0 (DDP) > Stage 1 > Stage 2 > Stage 2 + offload > Stage 3 > Stage 3 + offloads

从GPU内存使用角度来看 Stage 0 (DDP) < Stage 1 < Stage 2 < Stage 2 + offload < Stage 3 < Stage 3 + offloads

因此，当想要在适合最少数量的GPU的情况下获得最快的执行速度时，可以遵循以下过程。
我们从最快的方法开始，如果遇到GPU内存不足，然后转到下一个速度较慢但使用更少GPU内存的方法，依此类推。

具体方法
首先，将批量大小设置为1

启用 --gradient_checkpointing 1（HF Trainer）或直接使用 model.gradient_checkpointing_enable() - 如果出现内存不足（OOM），则

首先尝试使用ZeRO stage2。如果出现内存不足（OOM），则

尝试使用ZeRO stage2+ offload optimizer - 如果出现内存不足（OOM），则

切换到ZeRO stage3 - 如果出现内存不足（OOM），则

将 offload_param 启用到CPU - 如果出现内存不足（OOM），则

将 offload_optimizer 启用到CPU - 如果出现内存不足（OOM），则

使用混合精度进行训练而不是fp32

如果仍然出现内存不足（OOM），可以添加更多硬件或启用ZeRO-Infinity - 即将卸载 offload_param 和 offload_optimizer 切换到nvme。

性能优化
一旦批量大小为1不会导致内存不足，就可以测量有效吞吐量。

接下来，尝试将批量大小增加到尽可能大，因为批量大小越大，GPU的效率越高，因为它们在乘法的矩阵很大时表现最佳。

最后就可以不断进行性能优化。可以通过关闭一些卸载功能，或者在ZeRO阶段中降级，增加/减少批量大小，并再次测量有效吞吐量。
反复尝试，直到满意为止。

参考文献：

https://huggingface.co/docs/transformers/main/main_classes/deepspeed

https://www.deepspeed.ai/docs/config-json/

https://zhuanlan.zhihu.com/p/630734624

编辑于 2023-09-23 18:04・IP 属地北京